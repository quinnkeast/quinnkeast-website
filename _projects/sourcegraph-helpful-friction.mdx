---
title: "Helpful friction in connecting code hosts"
subtitle: "The unusual case of needing to slow folks down."
hero: "The unusual case of needing to slow folks down"
client: "Sourcegraph"
role: "Product Designer, Researcher"
period: "2022"
published: true
restricted: true
group: "sourcegraph"
size: "small"
ogImage:
  url: "/assets/blog/hello-world/cover.jpg"
thumbnail:
  url: "/assets/projects/ux-team.jpg"
---

- As a product designer, I often wish that we'd share more of the "small things" â€“ the efforts and projects that aren't big or noteworthy, but show how teams can solve small problems that have a real impact
- While working on (sourcegraph cloud), my team was solving the problem of organizations connecting to code hosts and choosing repositories to add to Sourcegraph for their team to access
- We'd determined early on that we would use GitHub and GitLab access tokens to establish these code host connections
- Because of how the permissions system worked, private code would never be visible to a user who didn't have access to that code on the code host. However, we also didn't have role-based access control, and did not plan to implement this for quite some time. This meant that in the earliest iteration of organizations on multitenant cloud, any member of an organization could view the list of repositories synced to Sourcegraph.
- We recommmended that organizations set up machine users ("fake users" on the code host that belong to the organization, with access only to a given set of repositories) and use access tokens via that machine user.
- However, we quickly learned in user testing and in working with early access customers that those setting up the organization wouldn't necessarily consider the recommendation for a variety of reasons, and would often simply set up the code host connection using their own personal access token.
- This set up a situation where, although private code would never be shown to someone who shouldn't see it, the **names** of all of that user's private repositories would be exposed to all members of their organization. Many of the early access customers, when informed about this, didn't feel this was an issue.
- However, in the absence of role-based access control, we felt that we needed to take responsibility for making sure that users were making an informed choice when they chose to use their own access token instead of that of a machine user.
- We captured this problem in a one-page design challenge: https://docs.google.com/document/d/1chbGEqkv4Z5f_YDe9PcCHYGbZU6GikNM/edit
- Then did some low-fidelity collaboration about how we might solve this, aligned on the approach.
- Then used the design system to quickly define the high-fidelity implementation.
- Outcome: in subsequent hands-on early access customer sessions, every single customer reviewed and commented on the recommendation to use a machine token. Some users decided to proceed with their own access token, acknowledging the risk, while others proceeded to set up a machine user.
- In the end, this isn't a flashy kind of case study: the result will never be connected to revenue or performance outcomes, and we will never be able to say we explicitly prevented a security incident. However, it was a real problem and we were able to deliver a real, minimal, and effective solution.
